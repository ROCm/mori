#!/usr/bin/env python3
"""
All2All SDMA Test using torch.distributed and multiprocessing
"""

import os
import numpy as np
import torch
import torch.distributed as dist
import mori.shmem as shmem
from mori.ccl import All2allSdma
from tests.python.utils import TorchDistContext, get_free_port


def _test_all2all(rank, world_size, port, elems, iterations, warmup):
    """Worker function for each process"""
    
    with TorchDistContext(rank=rank, world_size=world_size, master_port=port):
        shmem.shmem_torch_process_group_init("default")
        
        my_pe = shmem.shmem_mype()
        npes = shmem.shmem_npes()
        
        assert my_pe == rank, f"PE mismatch: {my_pe} != {rank}"
        assert npes == world_size, f"npes mismatch: {npes} != {world_size}"
        
        # Match C++ naming and logic
        elems_per_pe = elems  # Elements each PE sends to each target PE (like C++ elemsPerPe)
        bytes_per_pe = elems_per_pe * 4  # Bytes per PE chunk (like C++ bytesPerPe)
        total_bytes = bytes_per_pe * npes  # Total bytes per PE: all chunks combined (like C++ totalBytes)
        
        if rank == 0:
            print(f"\n{'='*60}")
            print(f"All2All SDMA Test")
            print(f"World size: {world_size}")
            print(f"Elements per PE: {elems_per_pe:,}")
            print(f"Data size: {total_bytes / (1024**2):.2f} MB per PE, {total_bytes * npes / (1024**2):.2f} MB total")
            print(f"Iterations: {iterations}" + (f" (warmup: {warmup})" if warmup > 0 else ""))
            print(f"{'='*60}\n")
        
        print(f"PE {rank}/{world_size}: SHMEM initialized, myPe={my_pe}, npes={npes}")

        # Create All2all object with sufficient buffer size
        # Use copy_output_to_user=False to test direct use of output_transit_buffer
        copy_output_to_user = True  # Set to False to use output_transit_buffer directly
        all2all = All2allSdma(my_pe, npes, 
                             input_buffer_size=total_bytes,
                             output_buffer_size=total_bytes,
                             copy_output_to_user=copy_output_to_user)
        print(f"PE {rank}: Created All2allSdma object (copy_output_to_user={copy_output_to_user})")

        # Allocate GPU memory
        # Note: Using torch.uint32 to match C++ All2allSdma<uint32_t>
        device = torch.device(f"cuda:{rank}")
        input_tensor = torch.zeros(elems_per_pe * npes, dtype=torch.uint32, device=device)
        output_tensor = torch.zeros(elems_per_pe * npes, dtype=torch.uint32, device=device)
        
        # Prepare data: PE i sends value (i+1)*1000 + j to PE j
        input_data_cpu = np.zeros(elems_per_pe * npes, dtype=np.uint32)
        for dest_pe in range(npes):
            value = (my_pe + 1) * 1000 + dest_pe
            input_data_cpu[dest_pe * elems_per_pe : (dest_pe + 1) * elems_per_pe] = value
        
        # Copy to GPU
        input_tensor.copy_(torch.from_numpy(input_data_cpu))

        if rank == 0:
            print(f"PE {rank}: Prepared input data with pattern: (src_pe+1)*1000 + dest_pe")
            print(f"  Sending to PE 0: {input_tensor[0].item()} (expected: {(my_pe+1)*1000 + 0})")
            print(f"  Sending to PE 1: {input_tensor[elems_per_pe].item()} (expected: {(my_pe+1)*1000 + 1})")

        # Create CUDA stream for all2all operations (similar to test_allgather.py)
        stream = torch.cuda.Stream(device=device)
        
        torch.cuda.synchronize()
        dist.barrier()

        # Execute All2All multiple times
        exec_times = []
        total_iters = warmup + iterations
        use_async = False  # Use async mode to match C++ test
        
        if not use_async:
            # Synchronous mode (single SDMA queue) - add timing and stream
            # Create CUDA events for timing
            all2all_start = torch.cuda.Event(enable_timing=True)
            all2all_end = torch.cuda.Event(enable_timing=True)
            
            for iter_idx in range(total_iters):
                # Record start time
                all2all_start.record(stream)
                
                with torch.cuda.stream(stream):
                    success = all2all(input_tensor, output_tensor, elems_per_pe, stream)
                
                # Record end time
                all2all_end.record(stream)
                
                # Synchronize to ensure all operations complete
                stream.synchronize()
                
                if not success:
                    print(f"PE {rank}: All2All operation failed at iteration {iter_idx}")
                    break
                
                # Calculate execution time
                all2all_time = all2all_start.elapsed_time(all2all_end) / 1000.0  # Convert ms to seconds
                
                if iter_idx >= warmup:
                    exec_times.append(all2all_time)
                    if rank == 0 and len(exec_times) == 1:
                        print(f"PE {rank}: First measurement iteration: {all2all_time:.6f}s")
                elif rank == 0:
                    print(f"Warmup iteration {iter_idx + 1}/{warmup}: {all2all_time:.6f}s")
        else:
            # Asynchronous mode (multiple SDMA queues, matches C++ test)
            if rank == 0:
                print(f"Using ASYNC mode (start_async + wait_async) to match C++ test")
                if warmup > 0:
                    print(f"Warmup iterations: {warmup}, Measurement iterations: {iterations}\n")
            
            for iter_idx in range(total_iters):
                if rank == 0 and (iter_idx == 0 or iter_idx == warmup):
                    stage = "Warmup" if iter_idx < warmup else "Measurement"
                    print(f"\n--- {stage} Iteration {iter_idx + 1} ---")
                
                dist.barrier()
                
                # Start async operation using context manager style (like test_allgather.py)
                with torch.cuda.stream(stream):
                    started = all2all.start_async(input_tensor, output_tensor, elems_per_pe, stream)
                if not started:
                    print(f"PE {rank}: Failed to start async operation")
                    break
                
                # Wait for completion (using the same stream)
                with torch.cuda.stream(stream):
                    exec_time = all2all.wait_async(stream)
                
                if exec_time < 0:
                    print(f"PE {rank}: Async operation failed")
                    break
                
                # Synchronize stream to ensure completion (like test_allgather.py)
                stream.synchronize()
                
                # Collect times after warmup
                if iter_idx >= warmup:
                    exec_times.append(exec_time)
                    if rank == 0 and len(exec_times) == 1:
                        print(f"PE {rank}: First measurement iteration: {exec_time:.6f}s")
                
                dist.barrier()

        # Calculate statistics from post-warmup iterations
        if len(exec_times) > 0:
            avg_time = np.mean(exec_times)
            min_time = np.min(exec_times)
            max_time = np.max(exec_times)
        else:
            avg_time = min_time = max_time = 0.0
        
        if rank == 0:
            print(f"\nPE {rank} local statistics:")
            print(f"  Min time: {min_time:.6f}s")
            print(f"  Max time: {max_time:.6f}s")
            print(f"  Avg time: {avg_time:.6f}s")

        # Get output transit buffer and verify
        # Pass the output_tensor to ensure the buffer is on the correct device
        output_transit_buffer = all2all.get_output_transit_buffer(device=output_tensor)
        output_transit_buffer_cpu = output_transit_buffer.cpu().numpy()
        
        if rank == 0:
            print(f"\nPE {rank}: Output transit buffer size: {output_transit_buffer.size(0)} elements")
            print(f"PE {rank}: Output transit buffer first 10 values: {output_transit_buffer_cpu[:10]}")
        
        # Verify results based on copy_output_to_user mode
        success = True
        expected_elements = total_bytes // 4
        
        if copy_output_to_user:
            # In COPY mode: verify output_tensor and output_transit_buffer match
            output_data_cpu = output_tensor.cpu().numpy()
            
            for src_pe in range(npes):
                chunk = output_data_cpu[src_pe * elems_per_pe : (src_pe + 1) * elems_per_pe]
                expected_value = (src_pe + 1) * 1000 + my_pe
                
                if not np.all(chunk == expected_value):
                    print(f"PE {rank}: Chunk from PE {src_pe} verification FAILED!")
                    print(f"  Expected all values = {expected_value}")
                    print(f"  Got first 10 values: {chunk[:10]}")
                    print(f"  Got unique values: {np.unique(chunk)}")
                    success = False
                elif rank == 0:
                    print(f"PE {rank}: Chunk from PE {src_pe} verified (all values = {expected_value})")
            
            # Verify output transit buffer contains the same data as output_tensor
            if output_transit_buffer_cpu.size >= expected_elements:
                transit_chunk = output_transit_buffer_cpu[:expected_elements]
                if np.array_equal(transit_chunk, output_data_cpu):
                    if rank == 0:
                        print(f"PE {rank}: Output transit buffer matches output_tensor ✓")
                else:
                    print(f"PE {rank}: Output transit buffer does NOT match output_tensor!")
                    print(f"  First 10 values in transit buffer: {transit_chunk[:10]}")
                    print(f"  First 10 values in output_tensor: {output_data_cpu[:10]}")
                    success = False
        else:
            # In non-COPY mode: verify output_transit_buffer directly (output_tensor may not be filled)
            if rank == 0:
                print(f"PE {rank}: Verifying output_transit_buffer directly (copy_output_to_user=False)")
            
            if output_transit_buffer_cpu.size >= expected_elements:
                transit_chunk = output_transit_buffer_cpu[:expected_elements]
                for src_pe in range(npes):
                    transit_buffer_chunk = transit_chunk[src_pe * elems_per_pe : (src_pe + 1) * elems_per_pe]
                    expected_value = (src_pe + 1) * 1000 + my_pe
                    if np.all(transit_buffer_chunk == expected_value):
                        if rank == 0:
                            print(f"  PE {rank}: Transit buffer chunk from PE {src_pe}: ✓ (all values = {expected_value})")
                    else:
                        print(f"PE {rank}: Transit buffer chunk from PE {src_pe}: ✗ FAILED!")
                        print(f"    Expected: {expected_value}, Got unique values: {np.unique(transit_buffer_chunk)}")
                        success = False
            else:
                if rank == 0:
                    print(f"PE {rank}: Output transit buffer size ({output_transit_buffer_cpu.size}) is smaller than expected ({expected_elements})")
                success = False

        # Synchronize stream before verification (like test_allgather.py)
        stream.synchronize()
        torch.cuda.synchronize()
        dist.barrier()
        min_time_tensor = torch.tensor([min_time], dtype=torch.float64)
        max_time_tensor = torch.tensor([max_time], dtype=torch.float64)
        avg_time_tensor = torch.tensor([avg_time], dtype=torch.float64)
        success_tensor = torch.tensor([1 if success else 0], dtype=torch.int32)
        
        dist.all_reduce(min_time_tensor, op=dist.ReduceOp.MIN)
        dist.all_reduce(max_time_tensor, op=dist.ReduceOp.MAX)
        dist.all_reduce(avg_time_tensor, op=dist.ReduceOp.SUM)
        dist.all_reduce(success_tensor, op=dist.ReduceOp.SUM)
        
        global_min = min_time_tensor.item()
        global_max = max_time_tensor.item()
        global_avg = avg_time_tensor.item() / npes
        passed_count = success_tensor.item()

        if rank == 0:
            global_bandwidth = total_bytes / global_max / (1024.0 * 1024.0 * 1024.0)
            
            print(f"\n=== Performance Statistics ===")
            print(f"Min time: {global_min:.6f}s")
            print(f"Max time: {global_max:.6f}s")
            print(f"Avg time: {global_avg:.6f}s")
            print(f"Bandwidth: {global_bandwidth:.2f} GB/s")
            print(f"Total data: {total_bytes / (1024.0 * 1024.0 * 1024.0):.3f} GB")
            print(f"\nPEs passed: {passed_count}/{npes}")
            
            if passed_count == npes:
                print(f"\n=== Test PASSED ===\n")
            else:
                print(f"\n=== Test FAILED ===\n")

        # Proper cleanup order to avoid race conditions
        torch.cuda.synchronize()  # 1. Ensure all GPU operations complete
        dist.barrier()             # 2. Synchronize all processes
        del all2all               # 3. Delete object (releases SHMEM buffers)
        dist.barrier()             # 4. Wait for all processes to finish cleanup
        shmem.shmem_finalize()    # 5. Finalize SHMEM (closes SDMA/HSA resources)
        
        if not success:
            raise AssertionError(f"PE {rank}: All2All verification failed")


def test_all2all(elems=67108864, world_size=8, iterations=10, warmup=10):
    """Run All2All SDMA test"""
    os.environ.setdefault('MORI_ENABLE_SDMA', '1')
    port = get_free_port()
    torch.multiprocessing.spawn(
        _test_all2all,
        args=(world_size, port, elems, iterations, warmup),
        nprocs=world_size,
        join=True,
    )


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Test All2All SDMA (similar to C++ example)",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument("--elems", type=int, default=67108864, help="Elements per PE")
    parser.add_argument("--world-size", type=int, default=8, help="Number of processes")
    parser.add_argument("--iterations", type=int, default=10, help="Number of iterations")
    parser.add_argument("--warmup", type=int, default=10, help="Warmup iterations")
    parser.add_argument("--enable-sdma", type=int, default=1, choices=[0, 1], help="Enable SDMA")
    args = parser.parse_args()
    os.environ['MORI_ENABLE_SDMA'] = str(args.enable_sdma)
    
    print(f"All2All SDMA Test")
    print(f"  Elements per PE: {args.elems:,}")
    print(f"  World size: {args.world_size}")
    print(f"  Iterations: {args.iterations}")
    print(f"  Warmup: {args.warmup}")
    print("-" * 60)
    
    test_all2all(args.elems, args.world_size, args.iterations, args.warmup)
