// Copyright Â© Advanced Micro Devices, Inc. All rights reserved.
//
// MIT License
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in all
// copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
// SOFTWARE.
#include "mori/application/transport/rdma/providers/mlx5/mlx5.hpp"

#include <hip/hip_runtime.h>
#include <infiniband/mlx5dv.h>
#include <infiniband/verbs.h>

#include <iostream>

#include "mori/application/utils/check.hpp"
#include "mori/application/utils/math.hpp"
#include "src/application/transport/rdma/providers/mlx5/mlx5_ifc.hpp"
#include "src/application/transport/rdma/providers/mlx5/mlx5_prm.hpp"

namespace mori {
namespace application {

/* ---------------------------------------------------------------------------------------------- */
/*                                        Device Attributes                                       */
/* ---------------------------------------------------------------------------------------------- */
HcaCapability QueryHcaCap(ibv_context* context) {
  int status;
  uint8_t cmd_cap_in[DEVX_ST_SZ_BYTES(query_hca_cap_in)] = {
      0,
  };
  uint8_t cmd_cap_out[DEVX_ST_SZ_BYTES(query_hca_cap_out)] = {
      0,
  };

  DEVX_SET(query_hca_cap_in, cmd_cap_in, opcode, MLX5_CMD_OP_QUERY_HCA_CAP);
  DEVX_SET(query_hca_cap_in, cmd_cap_in, op_mod, HCA_CAP_OPMOD_GET_CUR);

  status = mlx5dv_devx_general_cmd(context, cmd_cap_in, sizeof(cmd_cap_in), cmd_cap_out,
                                   sizeof(cmd_cap_out));
  assert(!status);

  HcaCapability hca_cap;

  hca_cap.portType = DEVX_GET(query_hca_cap_out, cmd_cap_out, capability.cmd_hca_cap.port_type);

  uint32_t logBfRegSize =
      DEVX_GET(query_hca_cap_out, cmd_cap_out, capability.cmd_hca_cap.log_bf_reg_size);
  hca_cap.dbrRegSize = 1LLU << logBfRegSize;

  return hca_cap;
}

/* ---------------------------------------------------------------------------------------------- */
/*                                          Mlx5CqContainer */
/* ---------------------------------------------------------------------------------------------- */
Mlx5CqContainer::Mlx5CqContainer(ibv_context* context, const RdmaEndpointConfig& config)
    : config(config) {
  int status;
  uint8_t cmd_in[DEVX_ST_SZ_BYTES(create_cq_in)] = {
      0,
  };
  uint8_t cmd_out[DEVX_ST_SZ_BYTES(create_cq_out)] = {
      0,
  };

  // Allocate user memory for CQ
  // TODO: accept memory allocated by user?
  cqeNum = config.maxCqeNum;
  int cqSize = RoundUpPowOfTwo(GetMlx5CqeSize() * cqeNum);
  // TODO: adjust cqe_num after aligning?
  cqSize = (cqSize + config.alignment - 1) / config.alignment * config.alignment;

  if (config.onGpu) {
    HIP_RUNTIME_CHECK(hipMalloc(&cqUmemAddr, cqSize));
    HIP_RUNTIME_CHECK(hipMemset(cqUmemAddr, 0, cqSize));
  } else {
    int status = posix_memalign(&cqUmemAddr, config.alignment, cqSize);
    memset(cqUmemAddr, 0, cqSize);
    assert(!status);
  }

  cqUmem = mlx5dv_devx_umem_reg(context, cqUmemAddr, cqSize, IBV_ACCESS_LOCAL_WRITE);
  assert(cqUmem);

  // Allocate user memory for CQ DBR (doorbell?)
  if (config.onGpu) {
    HIP_RUNTIME_CHECK(hipMalloc(&cqDbrUmemAddr, 8));
    HIP_RUNTIME_CHECK(hipMemset(cqDbrUmemAddr, 0, 8));
  } else {
    int status = posix_memalign(&cqDbrUmemAddr, 8, 8);
    memset(cqDbrUmemAddr, 0, 8);
    assert(!status);
  }

  cqDbrUmem = mlx5dv_devx_umem_reg(context, cqDbrUmemAddr, 8, IBV_ACCESS_LOCAL_WRITE);
  assert(cqDbrUmem);

  // Allocate user access region
  uar = mlx5dv_devx_alloc_uar(context, MLX5DV_UAR_ALLOC_TYPE_NC);
  assert(uar->page_id != 0);

  // Initialize CQ
  DEVX_SET(create_cq_in, cmd_in, opcode, MLX5_CMD_OP_CREATE_CQ);
  DEVX_SET(create_cq_in, cmd_in, cq_umem_valid, 0x1);
  DEVX_SET(create_cq_in, cmd_in, cq_umem_id, cqUmem->umem_id);

  void* cq_context = DEVX_ADDR_OF(create_cq_in, cmd_in, cq_context);
  DEVX_SET(cqc, cq_context, dbr_umem_valid, 0x1);
  DEVX_SET(cqc, cq_context, dbr_umem_id, cqDbrUmem->umem_id);
  DEVX_SET(cqc, cq_context, log_cq_size, LogCeil2(cqeNum));
  DEVX_SET(cqc, cq_context, uar_page, uar->page_id);

  uint32_t eqn;
  status = mlx5dv_devx_query_eqn(context, 0, &eqn);
  assert(!status);
  DEVX_SET(cqc, cq_context, c_eqn, eqn);

  cq = mlx5dv_devx_obj_create(context, cmd_in, sizeof(cmd_in), cmd_out, sizeof(cmd_out));
  assert(cq);

  cqn = DEVX_GET(create_cq_out, cmd_out, cqn);
}

Mlx5CqContainer::~Mlx5CqContainer() {
  mlx5dv_devx_umem_dereg(cqUmem);
  mlx5dv_devx_umem_dereg(cqDbrUmem);
  mlx5dv_devx_free_uar(uar);
  mlx5dv_devx_obj_destroy(cq);
}

/* ---------------------------------------------------------------------------------------------- */
/*                                         Mlx5QpContainer                                        */
/* ---------------------------------------------------------------------------------------------- */
Mlx5QpContainer::Mlx5QpContainer(ibv_context* context, const RdmaEndpointConfig& config,
                                 uint32_t cqn, uint32_t pdn)
    : context(context), config(config) {
  ComputeQueueAttrs(config);
  CreateQueuePair(cqn, pdn);
}

Mlx5QpContainer::~Mlx5QpContainer() { DestroyQueuePair(); }

void Mlx5QpContainer::ComputeQueueAttrs(const RdmaEndpointConfig& config) {
  // Receive queue attributes//
  rqAttrs.wqeSize = GetMlx5RqWqeSize();
  uint32_t maxMsgsNum = RoundUpPowOfTwo(config.maxMsgsNum);
  rqAttrs.wqSize = std::max(rqAttrs.wqeSize * maxMsgsNum, uint32_t(MLX5_SEND_WQE_BB));
  rqAttrs.wqeNum = ceil(rqAttrs.wqSize / rqAttrs.wqeSize);
  rqAttrs.wqeShift = log2(rqAttrs.wqeSize - 1) + 1;
  rqAttrs.offset = 0;

  // Send queue attributes
  sqAttrs.offset = rqAttrs.wqSize;
  sqAttrs.wqeSize = GetMlx5SqWqeSize();
  sqAttrs.wqSize = RoundUpPowOfTwo(sqAttrs.wqeSize * config.maxMsgsNum);
  sqAttrs.wqeNum = ceil(sqAttrs.wqSize / MLX5_SEND_WQE_BB);
  sqAttrs.wqeShift = MLX5_SEND_WQE_SHIFT;

  // Queue pair attributes
  qpTotalSize = RoundUpPowOfTwo(rqAttrs.wqSize + sqAttrs.wqSize);
  qpTotalSize = (qpTotalSize + config.alignment - 1) / config.alignment * config.alignment;

#if DEBUG == 1
  std::cout << "rq[ " << rqAttrs << "] sq[ " << sqAttrs << "]" << std::endl;
#endif
}

void Mlx5QpContainer::CreateQueuePair(uint32_t cqn, uint32_t pdn) {
  int status = 0;
  uint8_t cmd_in[DEVX_ST_SZ_BYTES(create_qp_in)] = {
      0,
  };
  uint8_t cmd_out[DEVX_ST_SZ_BYTES(create_qp_out)] = {
      0,
  };

  // Allocate user memory for QP

  if (config.onGpu) {
    HIP_RUNTIME_CHECK(hipMalloc(&qpUmemAddr, qpTotalSize));
    HIP_RUNTIME_CHECK(hipMemset(qpUmemAddr, 0, qpTotalSize));
  } else {
    status = posix_memalign(&qpUmemAddr, config.alignment, qpTotalSize);
    memset(qpUmemAddr, 0, qpTotalSize);
    assert(!status);
  }

  qpUmem = mlx5dv_devx_umem_reg(context, qpUmemAddr, qpTotalSize, IBV_ACCESS_LOCAL_WRITE);
  assert(qpUmem);

  // Allocate user memory for DBR (doorbell?)
  if (config.onGpu) {
    HIP_RUNTIME_CHECK(hipMalloc(&qpDbrUmemAddr, 8));
    HIP_RUNTIME_CHECK(hipMemset(qpDbrUmemAddr, 0, 8));
  } else {
    status = posix_memalign(&qpDbrUmemAddr, 8, 8);
    memset(qpDbrUmemAddr, 0, 8);
    assert(!status);
  }

  qpDbrUmem = mlx5dv_devx_umem_reg(context, qpDbrUmemAddr, 8, IBV_ACCESS_LOCAL_WRITE);
  assert(qpDbrUmem);

  // Allocate user access region
  qpUar = mlx5dv_devx_alloc_uar(context, MLX5DV_UAR_ALLOC_TYPE_NC);
  assert(qpUar);
  assert(qpUar->page_id != 0);

  if (config.onGpu) {
    uint32_t flag = hipHostRegisterPortable | hipHostRegisterMapped | hipHostRegisterIoMemory;
    HIP_RUNTIME_CHECK(hipHostRegister(qpUar->reg_addr, QueryHcaCap(context).dbrRegSize, flag));
    HIP_RUNTIME_CHECK(hipHostGetDevicePointer(&qpUarPtr, qpUar->reg_addr, 0));
  } else {
    qpUarPtr = qpUar->reg_addr;
  }

  // TODO: check for correctness
  uint32_t logRqSize = int(log2(rqAttrs.wqeNum - 1)) + 1;
  uint32_t logRqStride = rqAttrs.wqeShift - 4;
  uint32_t logSqSize = int(log2(sqAttrs.wqeNum - 1)) + 1;

  // Initialize QP
  DEVX_SET(create_qp_in, cmd_in, opcode, MLX5_CMD_OP_CREATE_QP);
  DEVX_SET(create_qp_in, cmd_in, wq_umem_id, qpUmem->umem_id);
  DEVX_SET64(create_qp_in, cmd_in, wq_umem_offset, 0);
  DEVX_SET(create_qp_in, cmd_in, wq_umem_valid, 0x1);

  void* qp_context = DEVX_ADDR_OF(create_qp_in, cmd_in, qpc);
  DEVX_SET(qpc, qp_context, st, MLX5_QPC_ST_RC);
  DEVX_SET(qpc, qp_context, pm_state, MLX5_QPC_PM_STATE_MIGRATED);
  DEVX_SET(qpc, qp_context, pd, pdn);
  DEVX_SET(qpc, qp_context, uar_page, qpUar->page_id);  // BF register
  DEVX_SET(qpc, qp_context, cqn_snd, cqn);
  DEVX_SET(qpc, qp_context, cqn_rcv, cqn);
  DEVX_SET(qpc, qp_context, log_sq_size, logSqSize);
  DEVX_SET(qpc, qp_context, log_rq_size, logRqSize);
  DEVX_SET(qpc, qp_context, log_rq_stride, logRqStride);
  DEVX_SET(qpc, qp_context, ts_format, 0x1);
  DEVX_SET(qpc, qp_context, cs_req, 0);
  DEVX_SET(qpc, qp_context, cs_res, 0);
  DEVX_SET(qpc, qp_context, dbr_umem_valid, 0x1);  // Enable dbr_umem_id
  DEVX_SET64(qpc, qp_context, dbr_addr,
             0);  // Offset of dbr_umem_id (behavior changed because of dbr_umem_valid)
  DEVX_SET(qpc, qp_context, dbr_umem_id, qpDbrUmem->umem_id);  // DBR buffer
  DEVX_SET(qpc, qp_context, page_offset, 0);

  qp = mlx5dv_devx_obj_create(context, cmd_in, sizeof(cmd_in), cmd_out, sizeof(cmd_out));
  assert(qp);

  qpn = DEVX_GET(create_qp_out, cmd_out, qpn);
}

void Mlx5QpContainer::DestroyQueuePair() {
  if (qpUmemAddr) HIP_RUNTIME_CHECK(hipFree(qpUmemAddr));
  if (qpDbrUmemAddr) HIP_RUNTIME_CHECK(hipFree(qpDbrUmemAddr));
  if (qpDbrUmem) mlx5dv_devx_umem_dereg(qpDbrUmem);
  if (qpUar) {
    hipPointerAttribute_t attr;
    HIP_RUNTIME_CHECK(hipPointerGetAttributes(&attr, qpUar->reg_addr));
    // Multiple qp may share the same uar address, only unregister once
    if ((attr.type == hipMemoryTypeHost) && (attr.hostPointer != nullptr)) {
      HIP_RUNTIME_CHECK(hipHostUnregister(qpUar->reg_addr));
    }
    mlx5dv_devx_free_uar(qpUar);
  }
  if (qp) mlx5dv_devx_obj_destroy(qp);
}

void* Mlx5QpContainer::GetSqAddress() { return static_cast<char*>(qpUmemAddr) + sqAttrs.offset; }

void* Mlx5QpContainer::GetRqAddress() { return static_cast<char*>(qpUmemAddr) + rqAttrs.offset; }

void Mlx5QpContainer::ModifyRst2Init() {
  uint8_t rst2init_cmd_in[DEVX_ST_SZ_BYTES(rst2init_qp_in)] = {
      0,
  };
  uint8_t rst2init_cmd_out[DEVX_ST_SZ_BYTES(rst2init_qp_out)] = {
      0,
  };

  DEVX_SET(rst2init_qp_in, rst2init_cmd_in, opcode, MLX5_CMD_OP_RST2INIT_QP);
  DEVX_SET(rst2init_qp_in, rst2init_cmd_in, qpn, qpn);

  void* qpc = DEVX_ADDR_OF(rst2init_qp_in, rst2init_cmd_in, qpc);
  DEVX_SET(qpc, qpc, rwe, 1); /* remote write access */
  DEVX_SET(qpc, qpc, rre, 1); /* remote read access */
  DEVX_SET(qpc, qpc, rae, 1);
  DEVX_SET(qpc, qpc, atomic_mode, 0x3);
  DEVX_SET(qpc, qpc, primary_address_path.vhca_port_num, config.portId);

  DEVX_SET(qpc, qpc, pm_state, 0x3);
  DEVX_SET(qpc, qpc, counter_set_id, 0x0);

  int status = mlx5dv_devx_obj_modify(qp, rst2init_cmd_in, sizeof(rst2init_cmd_in),
                                      rst2init_cmd_out, sizeof(rst2init_cmd_out));
  assert(!status);
}

void Mlx5QpContainer::ModifyInit2Rtr(const RdmaEndpointHandle& remote_handle,
                                     const ibv_port_attr& portAttr) {
  uint8_t init2rtr_cmd_in[DEVX_ST_SZ_BYTES(init2rtr_qp_in)] = {
      0,
  };
  uint8_t init2rtr_cmd_out[DEVX_ST_SZ_BYTES(init2rtr_qp_out)] = {
      0,
  };

  DEVX_SET(init2rtr_qp_in, init2rtr_cmd_in, opcode, MLX5_CMD_OP_INIT2RTR_QP);
  DEVX_SET(init2rtr_qp_in, init2rtr_cmd_in, qpn, qpn);

  void* qpc = DEVX_ADDR_OF(init2rtr_qp_in, init2rtr_cmd_in, qpc);
  DEVX_SET(qpc, qpc, mtu, portAttr.active_mtu);
  DEVX_SET(qpc, qpc, log_msg_max, 30);
  DEVX_SET(qpc, qpc, remote_qpn, remote_handle.qpn);
  DEVX_SET(qpc, qpc, next_rcv_psn, remote_handle.psn);
  DEVX_SET(qpc, qpc, min_rnr_nak, 12);
  DEVX_SET(qpc, qpc, log_rra_max, 20);

  qpc = DEVX_ADDR_OF(init2rtr_qp_in, init2rtr_cmd_in, qpc);
  DEVX_SET(qpc, qpc, primary_address_path.vhca_port_num, config.portId);

  // HcaCapability hca_cap = QueryHcaCap(context);
  if (portAttr.link_layer == IBV_LINK_LAYER_ETHERNET) {
    memcpy(DEVX_ADDR_OF(qpc, qpc, primary_address_path.rgid_rip), remote_handle.eth.gid,
           sizeof(remote_handle.eth.gid));

    memcpy(DEVX_ADDR_OF(qpc, qpc, primary_address_path.rmac_47_32), remote_handle.eth.mac,
           sizeof(remote_handle.eth.mac));
    DEVX_SET(qpc, qpc, primary_address_path.hop_limit, 64);
    DEVX_SET(qpc, qpc, primary_address_path.src_addr_index, config.gidIdx);
    DEVX_SET(qpc, qpc, primary_address_path.udp_sport, 0xC000);
  } else if (portAttr.link_layer == IBV_LINK_LAYER_INFINIBAND) {
    DEVX_SET(qpc, qpc, primary_address_path.rlid, remote_handle.ib.lid);
  } else {
    assert(false);
  }

  int status = mlx5dv_devx_obj_modify(qp, init2rtr_cmd_in, sizeof(init2rtr_cmd_in),
                                      init2rtr_cmd_out, sizeof(init2rtr_cmd_out));
  assert(!status);
}

void Mlx5QpContainer::ModifyRtr2Rts(const RdmaEndpointHandle& local_handle) {
  uint8_t rtr2rts_cmd_in[DEVX_ST_SZ_BYTES(rtr2rts_qp_in)] = {
      0,
  };
  uint8_t rtr2rts_cmd_out[DEVX_ST_SZ_BYTES(rtr2rts_qp_out)] = {
      0,
  };

  DEVX_SET(rtr2rts_qp_in, rtr2rts_cmd_in, opcode, MLX5_CMD_OP_RTR2RTS_QP);
  DEVX_SET(rtr2rts_qp_in, rtr2rts_cmd_in, qpn, qpn);

  void* qpc = DEVX_ADDR_OF(rtr2rts_qp_in, rtr2rts_cmd_in, qpc);
  DEVX_SET(qpc, qpc, log_sra_max, 20);
  DEVX_SET(qpc, qpc, next_send_psn, local_handle.psn);
  DEVX_SET(qpc, qpc, retry_count, 7);
  DEVX_SET(qpc, qpc, rnr_retry, 7);
  DEVX_SET(qpc, qpc, primary_address_path.ack_timeout, 20);
  DEVX_SET(qpc, qpc, primary_address_path.vhca_port_num, config.portId);

  int status = mlx5dv_devx_obj_modify(qp, rtr2rts_cmd_in, sizeof(rtr2rts_cmd_in), rtr2rts_cmd_out,
                                      sizeof(rtr2rts_cmd_out));
  assert(!status);
}

/* ---------------------------------------------------------------------------------------------- */
/*                                        Mlx5DeviceContext                                       */
/* ---------------------------------------------------------------------------------------------- */
Mlx5DeviceContext::Mlx5DeviceContext(RdmaDevice* rdma_device, ibv_pd* in_pd)
    : RdmaDeviceContext(rdma_device, in_pd) {
  mlx5dv_obj dv_obj{};
  mlx5dv_pd dvpd{};
  dv_obj.pd.in = pd;
  dv_obj.pd.out = &dvpd;
  int status = mlx5dv_init_obj(&dv_obj, MLX5DV_OBJ_PD);
  assert(!status);
  pdn = dvpd.pdn;
}

Mlx5DeviceContext::~Mlx5DeviceContext() {}

RdmaEndpoint Mlx5DeviceContext::CreateRdmaEndpoint(const RdmaEndpointConfig& config) {
  assert(!config.withCompChannel && !config.enableSrq && "not implemented");
  ibv_context* context = GetIbvContext();

  Mlx5CqContainer* cq = new Mlx5CqContainer(context, config);
  Mlx5QpContainer* qp = new Mlx5QpContainer(context, config, cq->cqn, pdn);

  RdmaEndpoint endpoint;
  endpoint.handle.psn = 0;
  endpoint.handle.portId = config.portId;

  HcaCapability hca_cap = QueryHcaCap(context);

  endpoint.handle.qpn = qp->qpn;
  if (hca_cap.IsEthernet()) {
    uint32_t out[DEVX_ST_SZ_DW(query_roce_address_out)] = {};
    uint32_t in[DEVX_ST_SZ_DW(query_roce_address_in)] = {};

    DEVX_SET(query_roce_address_in, in, opcode, MLX5_CMD_OP_QUERY_ROCE_ADDRESS);
    DEVX_SET(query_roce_address_in, in, roce_address_index, config.gidIdx);
    DEVX_SET(query_roce_address_in, in, vhca_port_num, config.portId);

    int status = mlx5dv_devx_general_cmd(context, in, sizeof(in), out, sizeof(out));
    assert(!status);

    memcpy(endpoint.handle.eth.gid,
           DEVX_ADDR_OF(query_roce_address_out, out, roce_address.source_l3_address),
           sizeof(endpoint.handle.eth.gid));

    memcpy(endpoint.handle.eth.mac,
           DEVX_ADDR_OF(query_roce_address_out, out, roce_address.source_mac_47_32),
           sizeof(endpoint.handle.eth.mac));
  } else if (hca_cap.IsInfiniBand()) {
    auto mapPtr = GetRdmaDevice()->GetPortAttrMap();
    auto it = mapPtr->find(config.portId);
    if (it != mapPtr->end() && it->second) {
      ibv_port_attr* port_attr = it->second.get();
      endpoint.handle.ib.lid = port_attr->lid;
    } else {
      assert(false && "Port attribute not found for given port ID");
    }
  } else {
    assert(false);
  }

  endpoint.vendorId = RdmaDeviceVendorId::Mellanox;

  endpoint.wqHandle.sqAddr = qp->GetSqAddress();
  endpoint.wqHandle.rqAddr = qp->GetRqAddress();
  endpoint.wqHandle.dbrRecAddr = qp->qpDbrUmemAddr;
  endpoint.wqHandle.dbrAddr = qp->qpUarPtr;
  endpoint.wqHandle.sqWqeNum = qp->sqAttrs.wqeNum;
  endpoint.wqHandle.rqWqeNum = qp->rqAttrs.wqeNum;

  endpoint.cqHandle.cqAddr = cq->cqUmemAddr;
  endpoint.cqHandle.consIdx = 0;
  endpoint.cqHandle.cqeNum = cq->cqeNum;
  endpoint.cqHandle.cqeSize = GetMlx5CqeSize();
  endpoint.cqHandle.dbrRecAddr = cq->cqDbrUmemAddr;

  cqPool.insert({cq->cqn, std::move(std::unique_ptr<Mlx5CqContainer>(cq))});
  qpPool.insert({qp->qpn, std::move(std::unique_ptr<Mlx5QpContainer>(qp))});

  return endpoint;
}

void Mlx5DeviceContext::ConnectEndpoint(const RdmaEndpointHandle& local,
                                        const RdmaEndpointHandle& remote) {
  uint32_t local_qpn = local.qpn;
  assert(qpPool.find(local_qpn) != qpPool.end());
  Mlx5QpContainer* qp = qpPool.at(local_qpn).get();
  RdmaDevice* rdmaDevice = GetRdmaDevice();
  const ibv_device_attr_ex* deviceAttr = rdmaDevice->GetDeviceAttr();
  const ibv_port_attr& portAttr = *(rdmaDevice->GetPortAttrMap()->find(local.portId)->second);
  qp->ModifyRst2Init();
  qp->ModifyInit2Rtr(remote, portAttr);
  qp->ModifyRtr2Rts(local);
}

/* ---------------------------------------------------------------------------------------------- */
/*                                           Mlx5Device                                           */
/* ---------------------------------------------------------------------------------------------- */
Mlx5Device::Mlx5Device(ibv_device* in_device) : RdmaDevice(in_device) {}
Mlx5Device::~Mlx5Device() {}

RdmaDeviceContext* Mlx5Device::CreateRdmaDeviceContext() {
  ibv_pd* pd = ibv_alloc_pd(defaultContext);
  return new Mlx5DeviceContext(this, pd);
}

}  // namespace application
}  // namespace mori
